# ğŸ§  Agentic Knowledge Graph System
### End-to-End Research Intelligence Platform â€” 100% Local with Ollama LLM

> Build, query, and reason over scientific knowledge graphs â€” entirely on your local machine.
> No API keys. No cloud. Just powerful local AI.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENTIC KG SYSTEM                            â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“¥ INPUT SOURCES          ğŸ¤– AI AGENTS             ğŸ“¤ OUTPUT  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   ArXiv     â”‚          â”‚  Research   â”‚          â”‚  Q&A   â”‚  â”‚
â”‚  â”‚ Semantic S. â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Agent     â”‚â”€â”€â”€â”€â”€â”€â”   â”‚ Hypo.  â”‚  â”‚
â”‚  â”‚ Local PDFs  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚ Review â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚               â”‚
â”‚                            â”‚ Extraction  â”‚     â–¼               â”‚
â”‚                            â”‚   Agent     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚  Knowledge   â”‚   â”‚
â”‚                                   â”‚         â”‚    Graph     â”‚   â”‚
â”‚  ğŸ§  LOCAL LLM              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚  (Neo4j /   â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  Reasoning  â”‚  â”‚  NetworkX)  â”‚   â”‚
â”‚  â”‚   Ollama    â”‚          â”‚   Agent     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚ llama3.1:8b â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â”‚ nomic-embed â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. Install Ollama (Local LLM)
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Download from https://ollama.ai

# Start Ollama
ollama serve

# Pull required models
ollama pull llama3.1:8b          # Main reasoning model (~4.7GB)
ollama pull llama3.2:3b          # Lightweight alternative (~2GB)
ollama pull nomic-embed-text     # Embedding model (~274MB)
```

### 2. Install & Run the System
```bash
# Clone or download this project
cd agentic-kg-system

# Run automated setup
chmod +x setup.sh && ./setup.sh

# OR manual install:
pip install -r requirements.txt

# Launch Web UI
streamlit run ui/app.py
# â†’ Open: http://localhost:8501
```

### 3. Optional: Neo4j (Persistent Graph)
```bash
# With Docker (recommended)
docker-compose up -d neo4j
# Neo4j Browser: http://localhost:7474
# Username: neo4j | Password: password123

# Without Docker: https://neo4j.com/download/
```

---

## ğŸ“ Project Structure

```
agentic-kg-system/
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_engine.py        # Ollama LLM interface (generate, embed, chat)
â”‚   â””â”€â”€ orchestrator.py      # Master pipeline coordinator
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ research_agent.py    # Fetch papers (ArXiv, Semantic Scholar, PDFs)
â”‚   â”œâ”€â”€ extraction_agent.py  # Extract entities, relations, claims with LLM
â”‚   â””â”€â”€ reasoning_agent.py   # Q&A, hypotheses, literature review
â”‚
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ knowledge_graph.py   # Neo4j + NetworkX fallback graph
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py               # Streamlit web interface
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py          # System configuration
â”‚
â”œâ”€â”€ cli.py                   # Command line interface
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ docker-compose.yml       # Neo4j container
â””â”€â”€ setup.sh                 # Automated setup script
```

---

## ğŸ’» CLI Usage

```bash
# Check system status
python cli.py setup

# Research a topic (fetches & processes papers automatically)
python cli.py research "transformer attention mechanisms" --max-papers 15
python cli.py research "CRISPR gene therapy" --sources arxiv,semantic_scholar
python cli.py research "quantum computing" --year-from 2022 --output results.json

# Load local PDF papers
python cli.py research "my topic" --local-dir /path/to/my/papers/

# Ask questions about your knowledge graph
python cli.py ask "What are the main challenges in this field?"
python cli.py ask "Which methods show the best performance?"

# Generate novel research hypotheses
python cli.py hypotheses "protein folding mechanisms"

# Auto-generate literature review
python cli.py review "deep reinforcement learning" --style survey -o review.md
python cli.py review "cancer immunotherapy" --style executive

# Interactive chat
python cli.py chat

# View graph statistics
python cli.py stats
```

---

## ğŸŒ Web UI Features

| Tab | Feature |
|-----|---------|
| ğŸ”¬ Research Pipeline | Automated paper fetching, extraction, and KG building |
| ğŸ’¬ Chat & Q&A | Conversational interface with KG-grounded answers |
| ğŸ—ºï¸ Knowledge Graph | Browse, search, visualize your knowledge graph |
| ğŸ’¡ Hypotheses | AI-generated novel research hypotheses |
| ğŸ“– Literature Review | Auto-generated literature reviews (4 styles) |
| ğŸ“Š Analytics | System stats, node/edge counts, session tracking |

---

## âš™ï¸ Configuration

Edit `config/settings.py` to customize:

```python
# Change LLM model
CONFIG.ollama.primary_model = "llama3.1:70b"    # More powerful
CONFIG.ollama.primary_model = "mistral:7b"       # Alternative
CONFIG.ollama.primary_model = "phi3:mini"        # Fastest

# Adjust pipeline settings
CONFIG.agents.max_research_papers = 20
CONFIG.agents.confidence_threshold = 0.8

# Neo4j credentials
CONFIG.neo4j.password = "your_password"
```

---

## ğŸ¤– Supported Ollama Models

| Model | Size | Best For |
|-------|------|----------|
| `llama3.1:8b` | 4.7GB | Best balance (recommended) |
| `llama3.2:3b` | 2.0GB | Fast, lower RAM systems |
| `llama3.1:70b` | 40GB | Best quality (needs GPU) |
| `mistral:7b` | 4.1GB | Great reasoning |
| `phi3:mini` | 2.3GB | Very fast, good quality |
| `gemma2:9b` | 5.4GB | Strong analytical |
| `qwen2.5:7b` | 4.4GB | Excellent multilingual |
| `nomic-embed-text` | 274MB | Embeddings (required) |

---

## ğŸ”§ System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 8GB | 16GB+ |
| Storage | 10GB | 50GB+ |
| CPU | Any modern | 8+ cores |
| GPU | Not required | NVIDIA (speeds up LLM) |
| Python | 3.10+ | 3.11+ |

---

## ğŸ”¬ Example Research Workflow

```
1. Start: "I want to understand Graph Neural Networks for drug discovery"

2. System automatically:
   â”œâ”€â”€ Fetches 15 papers from ArXiv + Semantic Scholar
   â”œâ”€â”€ Extracts 200+ entities (proteins, algorithms, datasets, methods)
   â”œâ”€â”€ Finds 150+ relations (method USES dataset, paper EXTENDS theory)
   â”œâ”€â”€ Identifies 50+ scientific claims and findings
   â””â”€â”€ Builds a rich knowledge graph

3. You can then:
   â”œâ”€â”€ Ask: "What GNN architectures work best for molecular graphs?"
   â”œâ”€â”€ Ask: "What datasets are most commonly used?"
   â”œâ”€â”€ Generate: Novel hypotheses about unexplored drug-protein interactions
   â”œâ”€â”€ Write: Full literature review in academic style
   â””â”€â”€ Export: Knowledge graph as JSON/GraphML for further analysis
```

---

## ğŸ“Š Knowledge Graph Schema

```
Nodes:
  (:Paper)      - Research papers with title, abstract, year, authors
  (:Author)     - Researchers with name, affiliation
  (:Concept)    - Scientific concepts and ideas
  (:Method)     - Research methods and algorithms
  (:Dataset)    - Datasets used in research
  (:Entity)     - Any scientific entity (chemicals, genes, etc.)
  (:Hypothesis) - Claims, findings, and generated hypotheses
  (:Topic)      - Top-level research topics

Relations:
  AUTHORED_BY, CITES, USES_METHOD, HAS_ENTITY
  MAKES_CLAIM, RELATED_TO, EXTENDS, CONTRADICTS
  SUPPORTS, USES_DATASET, PART_OF, HAS_PAPER
```

---

## ğŸ› ï¸ Troubleshooting

**Ollama not connecting:**
```bash
ollama serve   # Must be running in background
ollama list    # Check available models
```

**No papers found:**
- Check internet connection (ArXiv/S2 require internet)

- Try different search terms
- Use local PDFs with `--local-dir`

**Slow performance:**
- Use smaller model: `llama3.2:3b`
- Reduce `--max-papers`
- Enable GPU in Ollama: `CUDA_VISIBLE_DEVICES=0 ollama serve`

**Neo4j issues:**
- System works fine without Neo4j (uses in-memory graph)
- For persistence, use Docker: `docker-compose up -d neo4j`

---

